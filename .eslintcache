[{"C:\\Users\\vaibh\\Desktop\\trynotttolaugh\\src\\index.js":"1","C:\\Users\\vaibh\\Desktop\\trynotttolaugh\\src\\App.js":"2","C:\\Users\\vaibh\\Desktop\\trynotttolaugh\\src\\reportWebVitals.js":"3","C:\\Users\\vaibh\\Desktop\\trynotttolaugh\\src\\TestComponent.js":"4","C:\\Users\\vaibh\\Desktop\\trynotttolaugh\\src\\JokeCompnent.js":"5"},{"size":517,"mtime":1610111151540,"results":"6","hashOfConfig":"7"},{"size":290,"mtime":1610867475658,"results":"8","hashOfConfig":"7"},{"size":375,"mtime":1610111151542,"results":"9","hashOfConfig":"7"},{"size":2819,"mtime":1610867857492,"results":"10","hashOfConfig":"7"},{"size":1303,"mtime":1610982722352,"results":"11","hashOfConfig":"7"},{"filePath":"12","messages":"13","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"14"},"s7ate5",{"filePath":"15","messages":"16","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"14"},{"filePath":"17","messages":"18","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"14"},{"filePath":"19","messages":"20","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"21","usedDeprecatedRules":"14"},{"filePath":"22","messages":"23","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},"C:\\Users\\vaibh\\Desktop\\trynotttolaugh\\src\\index.js",[],["24","25"],"C:\\Users\\vaibh\\Desktop\\trynotttolaugh\\src\\App.js",[],"C:\\Users\\vaibh\\Desktop\\trynotttolaugh\\src\\reportWebVitals.js",[],"C:\\Users\\vaibh\\Desktop\\trynotttolaugh\\src\\TestComponent.js",["26"],"import React, { useEffect, useRef } from \"react\";\r\nimport * as faceapi from \"face-api.js\";\r\n\r\nfunction TestComponent() {\r\n  const video = useRef();\r\n  const counter = useRef();\r\n  var temp;\r\n  var isStarted = false;\r\n\r\n  const initCamera = async (width, height) => {\r\n    console.log(\"initing camera\");\r\n    video.current.width = width;\r\n    video.current.height = height;\r\n    const stream = await navigator.mediaDevices.getUserMedia({\r\n      audio: false,\r\n      video: {\r\n        facingMode: \"user\",\r\n        width: width,\r\n        height: height,\r\n      },\r\n    });\r\n    video.current.srcObject = stream;\r\n    return new Promise((resolve) => {\r\n      video.current.onloadedmetadata = () => {\r\n        resolve(video);\r\n      };\r\n    });\r\n  };\r\n\r\n  useEffect(() => {\r\n    initCamera(320, 240).then((video) => {\r\n      console.log(\"Camera was initialized\");\r\n    });\r\n\r\n  \r\n  });\r\n\r\n  const start = () => {\r\n    isStarted = true;\r\n    const MODEL_URL = process.env.PUBLIC_URL + \"/models\";\r\n\r\n    Promise.all([\r\n      faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\r\n      faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\r\n      faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\r\n      faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),\r\n    ]).then(() => {\r\n      console.log(\"started reading\");\r\n      if (!temp) {\r\n        temp = setInterval(async () => {\r\n          let happiness;\r\n\r\n          try {\r\n            const detections = await faceapi\r\n              .detectSingleFace(\r\n                video.current,\r\n                new faceapi.TinyFaceDetectorOptions()\r\n              )\r\n              .withFaceExpressions();\r\n            if (detections.expressions.hasOwnProperty(\"happy\")) {\r\n              happiness = detections.expressions.happy;\r\n            }\r\n\r\n            if (happiness > 0.7) {\r\n              console.log(\"you smiled!\");\r\n            }\r\n          } catch (e) {\r\n            console.log(e);\r\n          }\r\n          // const resizedDetections = faceapi.resizeResults(detections, displaySize)\r\n          // canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height)\r\n          // faceapi.draw.drawDetections(canvas, resizedDetections)\r\n          // faceapi.draw.drawFaceLandmarks(canvas, resizedDetections)\r\n          // faceapi.draw.drawFaceExpressions(canvas, resizedDetections)\r\n        }, 100);\r\n      }\r\n    });\r\n  };\r\n\r\n  return (\r\n    <div>\r\n      <h1 ref={counter}></h1>\r\n      <button onClick={start}>start</button>\r\n      <button\r\n        onClick={() => {\r\n          if (isStarted) {\r\n            clearInterval(temp);\r\n          }\r\n          isStarted = false;\r\n          temp = false\r\n        }}\r\n      >\r\n        stop\r\n      </button>\r\n      <video ref={video} autoPlay muted playsInline></video>\r\n    </div>\r\n  );\r\n}\r\n\r\nexport default TestComponent;\r\n","C:\\Users\\vaibh\\Desktop\\trynotttolaugh\\src\\JokeCompnent.js",["27"],{"ruleId":"28","replacedBy":"29"},{"ruleId":"30","replacedBy":"31"},{"ruleId":"32","severity":1,"message":"33","line":82,"column":7,"nodeType":"34","endLine":82,"endColumn":25},{"ruleId":"35","severity":1,"message":"36","line":38,"column":11,"nodeType":"37","endLine":38,"endColumn":41},"no-native-reassign",["38"],"no-negated-in-lhs",["39"],"jsx-a11y/heading-has-content","Headings must have content and the content must be accessible by a screen reader.","JSXOpeningElement","react-hooks/exhaustive-deps","Assignments to the 'msg' variable from inside React Hook useEffect will be lost after each render. To preserve the value over time, store it in a useRef Hook and keep the mutable value in the '.current' property. Otherwise, you can move this variable directly inside useEffect.","NewExpression","no-global-assign","no-unsafe-negation"]